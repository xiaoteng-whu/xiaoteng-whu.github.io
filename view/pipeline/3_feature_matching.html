<section>
    <div class="container">
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h1 class="text-center">Features Matching</h1>
                <p>
                    The objective of this step is to match all features between candidate image pairs.
                </p>
                <p>
                    First, we perform photometric matches between the set of descriptors from the 2 input images.
                    For each feature in image A, we obtain a list of candidate features in image B.
                    As the descriptor space is not a linear and well defined space, we cannot rely on absolute distance values to know if the match is valid or not (we can only have an absolute higher bound distance).
                    To remove bad candidates, we assume that thereâ€™s only one valid match in the other image.
                    So for each feature descriptor on the first image, we look for the 2 closest descriptors and we use a relative threshold between them.
                    This assumption will kill features on repetitive structure but has proved to be a robust criterion <a class="ref_link" data-ref="#Lowe2004">[Lowe2004]</a>.
                    This provide a list of feature matching candidates based only on a photometric criterion.
                    Find the 2 closest descriptors in the second image for each feature is computationally intensive with a brute force approach, but many optimized algorithms exists.
                    The most common one is Approximate Nearest Neighbor, but there are alternatives like, Cascading Hashing.
                </p>
                <p>
                    Then, we use the features positions in the images to make a geometric filtering by using epipolar geometry in an outlier detection framework called RANSAC (RANdom SAmple Consensus).
                    We randomly select a small set of feature correspondences and compute the fundamental (or essential) matrix, then we check the number of features that validates this model and iterate through the RANSAC framework.
                </p>
                <div class="references pmd-card pmd-card-default pmd-z-depth up_margin">
                    <div class="pmd-card-title">
                        <h2 class="pmd-card-title-text">References</h2>
                    </div>
                    <div class="pmd-card-body">
                        <div class="table-responsive">
                            <table class="table">
                                <tbody>
                                <tr>
                                    <td data-title="code" id="Lowe2004">[Lowe2004]</td>
                                    <td data-title="name"><a target="_blank" href="http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf">Distinctive image features from scale-invariant keypoints, David G. Lowe, 2004</a></td>
                                </tr>
                                <tr>
                                    <td data-title="code" id="Flann2009">[FLANN2009]</td>
                                    <td data-title="name">Fast Approximate Nearest Neighbors with Automatic Algorithm Configuration. Muja, Marius, and David G. Lowe. VISAPP (1). 2009</td>
                                </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>